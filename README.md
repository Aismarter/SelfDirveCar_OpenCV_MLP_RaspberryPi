# SelfDirveCar_OpenCV_MLP_RaspberryPi
基于树莓派与Opencv和MLP神经网络搭建的自动驾驶小车(Self driving car based on raspberry pie and opencv and MLP Neural Network)

本项目采用的机器学习的MLP算法，本质上是一个多分类问题。系统复杂度低，集成性高。

这个项目是基于OpenCV和树莓派的一个自动驾驶小车的系统设计与实现。项目整体分为两个部分，基于树莓派的硬件部分与基于opencv的算法部分。
OpenCV在该项目中主要使用在2个方面：1、对输入图像的处理，调用了CV中的灰度化、感兴趣的区域选取等方法；2、神经网络算法 ，调用了opencv的ML库中的多层感知机模型（MLP）来对输入图像进行分类。
树莓派在该项目中主要用在2个方面：1、配合树莓派摄像头收集信息，2、通过socket与上位机通讯。
另外，项目中的小车的硬件还使用了arduino、蓝牙、电机驱动器等模块。目的是通过蓝牙连接arduinoh和我的电脑，使我的电脑可以通过蓝牙发送指令给arduino来控制小车的前进、后退等行为。


想要实现这个项目，首先，自然需要搭建好一个小车。
该小车在搭建使用的硬件模块清单如下：
树莓派3b+， 树莓派原装摄像头， 包含电机的小车车体， 电机驱动模块，arduino nano开发版， 蓝牙主机模块， 蓝牙从机模块。
小车整体硬件主要的部分为以上所示但要做完整的小车搭建，还是需要一些其他实验工具来为小车做焊接固定、调试模块等工序的。
因此诸如电烙铁、螺钉、USB转TLL模块也是需要准备的。

其次，在小车硬件环境搭建好后，就需要完成AI算法的软件部分来实现我们的自动驾驶功能。
遵循AI开发的数据收集->模型训练->模型部署的原则，我们的软件部分也分为以下3部分：
1.收集训练数据的程序
2.训练算法模型的程序
3.模型部署应用的程序
这三个部分，分别对应着我项目中的三个.py文件。每个代码都能实现以上对应的功能。

其中，在采集训练数据阶段，我使用电脑通过蓝牙模块无线控制小车，在规定的跑道上行驶一圈。
树莓派与摄像头会在这段时间一直开启，如果我按下电脑上指定小车前进的按键后，小车就会向前一步，同时保存下按下按键时刻的视频帧作为训练图片和前进指令作为标签。
这样，当我绕实验环境的地形多行驶几圈后，小车就会收集够足够的带标签的训练数据。
项目上传的目录中，有我之前已经收集到数据集。

运行训练算法模型的程序，我们就可以将MLP模型通过搜集好的训练数据，在上位机上训练了。
但这里，我们使用的仅仅只是机器学习方法来实现预期的自动驾驶功能，实际上就是收集完图片再进行一次多分类的过程。
因此，数据的处理，需要手动做特征提取与转换，最终才能得到可被模型接受的数据。
训练之后，就可以得到mlp在我们获取的数据集的参数模型了。

最后，将模型应用到我们的作用场景下，就可以实现小车自动驾驶功能了。
在这里又有2点需要强调一下。1、首先，在小车自动驾驶的应用过程中，是复用了在收集训练数据中树莓派摄像头一直获取数据摄像头数据的代码的。
这段代码运行在树莓派里，通过socket与上位机通讯，一直将摄像头所看见的视频帧发送到上位机去处理。上位机收到图片，就调用MLP的模型参数，输出检测的结果。
2、其次，上位机输出的检测结果，是通过蓝牙发送arduino来控制小车的运转的。
这样，我的电脑作为服务器，一直监听小车上树莓派发送过来的摄像头捕获的数据。一旦收到数据，就在上位机执行inference过程，并通过蓝牙将数据发送给小车的arduino控制电机驱动模块。
于是，小车将通过树莓派将数据传送到电脑上，电脑执行完推理过程得到下一步下车要运行的结果，再通过蓝牙将控制信息发送给小车，让小车做出前进、后退等行动。
通过这种机制，将小车放在一个特定的环境下，下车就可以根据现场的环境信息，来自动做出或是前进、或是停止的行为了。
